#!/usr/bin/env python
PACKAGE = "pacman_vision"
from dynamic_reconfigure.parameter_generator_catkin import *

reconfigure = ParameterGenerator()
node = reconfigure.add_group("Base Node Filters")
estimator = reconfigure.add_group("Estimator Module")
broadcaster = reconfigure.add_group("Broadcaster Module")
tracker = reconfigure.add_group("Tracker Module")
listener = reconfigure.add_group("Listener Module")
supervox = reconfigure.add_group("Supervoxels Module")
scanner = reconfigure.add_group("Pose Scanner Module")

resolution_enum = reconfigure.enum([ reconfigure.const("SD",   int_t, 0,   "Listen to kinect2 low resolution point cloud"),
                       reconfigure.const("QHD",   int_t, 1,   "Listen to kinect2 quarter HD point cloud"),
                       reconfigure.const("HD",  int_t, 2,   "Listen to kinect2 full HD point cloud")],
                       "Chose Point Cloud resolution to listen to (relevant for kinect2_bridge only)")
sensor_enum = reconfigure.enum([ reconfigure.const("Internal_Kinect2_Processor",   int_t, 0,   "Use internal kinect2 processor"),
                       reconfigure.const("External_Kinect2_Bridge",   int_t, 1,   "Listen to kinect2_bridge published topics"),
                       reconfigure.const("External_Openni2_Camera",  int_t, 2,   "Listen to openni2 published topics")],
                       "Chose which sensor driver to use")
#           Name    Type  ReconfigureLevel    Description   Default   Min   Max
reconfigure.add("Master_Disable", bool_t, 0, "Disable the whole node and all modules", False)
reconfigure.add("sensor_type", int_t, 0, "Chose which sensor to use Kinect2 or openni2, internal or external", 0,0,2, edit_method=sensor_enum)
reconfigure.add("external_kinect2_resolution", int_t, 0, "Choose Point Cloud resolution from kinect2_bridge", 0,0,2, edit_method=resolution_enum)
reconfigure.add("enable_estimator", bool_t, 0, "Enable Estimator module", False)
reconfigure.add("enable_tracker", bool_t, 0, "Enable Tracker module", False)
reconfigure.add("enable_broadcaster", bool_t, 0, "Enable Broadcaster module", False)
reconfigure.add("enable_listener", bool_t, 0, "Enable Listener module", False)
reconfigure.add("enable_supervoxels", bool_t, 0, "Enable Supervoxels module", False)
reconfigure.add("enable_scanner", bool_t, 0, "Enable Pose Scanner module", False)
#Node
node.add("keep_organized", bool_t, 0, "Keep the point cloud organized during various filters, if possible (voxel grid breaks organized structure of point cloud).", False)
node.add("passthrough", bool_t, 0, "Enable Passthrough filter to the scene", True)
node.add("pass_xmin", double_t, 0, "Passthrough filter lower bound for X (in meters)", -0.5, -5.0, 5.0)
node.add("pass_xmax", double_t, 0, "Passthrough filter upper bound for X (in meters)", 0.5, -5.0, 5.0)
node.add("pass_ymin", double_t, 0, "Passthrough filter lower bound for Y (in meters)", -0.5, -5.0, 5.0)
node.add("pass_ymax", double_t, 0, "Passthrough filter upper bound for Y (in meters)", 0.5, -5.0, 5.0)
node.add("pass_zmin", double_t, 0, "Passthrough filter lower bound for Z (in meters)", 0.2, 0.1, 10.0)
node.add("pass_zmax", double_t, 0, "Passthrough filter upper bound for Z (in meters)", 1.0, 0.0, 10.0)
node.add("downsampling", bool_t, 0, "Enable VoxelGrid filter to the scene, applied AFTER the eventual passthrough filter.", False)
node.add("downsample_leaf_size", double_t, 0, "VoxelGrid filter leaf size (in meters)", 0.005, 0.001, 0.1)
node.add("plane_segmentation", bool_t, 0, "Enable RANSAC fitting for plane and removal of found plane, applied AFTER eventual passthrough and downsampling filters.", False)
node.add("plane_tolerance", double_t, 0, "Plane segmentation tolerance (in meters)", 0.004, 0.00, 0.5)

#Listener
listener.add("crop_right_arm", bool_t, 0, "Listen to and filter out Vito right arm from the scene", False)
listener.add("crop_left_arm", bool_t, 0, "Listen to and filter out Vito left arm from the scene", False)
listener.add("crop_right_hand", bool_t, 0, "Listen to and filter out Vito right hand from the scene", False)
listener.add("crop_left_hand", bool_t, 0, "Listen to and filter out Vito left hand from the scene", False)
listener.add("use_table_transform", bool_t, 0, "Use Table Workbench read from Vito to model a Passthrough filter around it", False)

#Estimator
estimator.add("object_calibration", bool_t, 0, "Enable this flag only when performing object-star calibration. When this flag is enabled all estimated objects will be called <object>(for compatibility with calibration package).", False)
estimator.add("iterations", int_t, 0, "Control Pose Estimation iterations, during candidate refinement with Progressive Bisection. (Increasing this value will increase estimation time)", 5, 1, 100)
estimator.add("neighbors", int_t, 0, "Control how many neighbors are retrived from pose estimation database, each retrieved neighbor will then be refined with Progressive Bisection. (Increasing this value may improve recognition at the cost of execution time)", 10, 1, 100)
estimator.add("cluster_tol", double_t, 0, "Euclidean clustering tolerance (in meters), used to separate object clusters during table top segmentation.", 0.05, 0.001, 0.5)

#Broadcaster
broadcaster.add("publish_tf", bool_t, 0, "When true all tf transforms computed gets broadcasted.", True)
broadcaster.add("estimated_objects", bool_t, 0, "When true broadcast markers of currently estimated and/or tracked objects.", True)
broadcaster.add("passthrough_limits", bool_t, 0, "When true broadcast a marker, picturing passthrough filter limits.", True)
broadcaster.add("tracker_bounding_box", bool_t, 0, "When true broadcast a marker, picturing a bounding box around the object currently tracked.", True)

#Tracker
tracker.add("tracker_disturbance", bool_t, 0, "Trigger a manual disturbance to tracker (Relevant only if it is enabled).", False)
type_enum = reconfigure.enum([ reconfigure.const("DQ",   int_t, 0,   "Use Dual Quaternion method to estimate transformations"),
                       reconfigure.const("LM",   int_t, 1,   "Use Levenberg Marquardt method to estimate transformations"),
                       reconfigure.const("SVD",  int_t, 2,   "Use SVD-based method to estimate transformations"),
                       reconfigure.const("LLS",  int_t, 3,   "Use Linear Least Squares method to estimate transformations")],
                       "Chose transformation estimation type for Tracker")
tracker.add("estimation_type", int_t, 0, "Control which method to use during tracker transformation estimation. The chosen method is used to compute a transformation between source-target correspondences. (Relevant only if Tracker module is enabled)", 0,0,3, edit_method=type_enum)

#Supervoxels
supervox.add("use_service", bool_t, 0, "When true, perform Supervoxel segmentation only when the user calls the service. When false, perform it at every step.", False)
supervox.add("voxel_resolution", double_t, 0, "Set Voxel resolution (in meters) to apply to the segmentation procedure. This parameter should be much less than Seed resolution below", 0.02, 0.001, 0.3)
supervox.add("seed_resolution", double_t, 0, "Set Seed resolution (in meters) to apply to the segmentation procedure. This parameter should be much greater than Voxel resolution above", 0.2, 0.01, 3)
supervox.add("color_importance", double_t, 0, "Set Color importance to apply to the segmentation procedure", 0.3333, 0.0001, 100)
supervox.add("spatial_importance", double_t, 0, "Set Spatial importance to apply to the segmentation procedure", 0.3333, 0.0001, 100)
supervox.add("normal_importance", double_t, 0, "Set Normal importance to apply to the segmentation procedure", 0.3333, 0.0001, 100)
supervox.add("refinement_iterations", int_t, 0, "Number of iterations during refinement", 2, 0, 10)
supervox.add("normals_search_radius", double_t, 0, "Search radius to consider when computing normals, adjust it considering the voxel resolution you set", 0.015, 0.001, 0.3)

#Pose Scanner
scanner.add("ignore_clicked_point", bool_t, 0, "When true, ignore any further published clicked point, for not accidentally overwrite table transformation", False)
scanner.add("work_dir", str_t, 0, "Base directory to store poses and transformations", "~/PoseScanner")
scanner.add("table_pass", int_t, 0, "Turn Table pass angle in degrees", 10, 1, 180)

exit(reconfigure.generate(PACKAGE, "pacman_vision", "pacman_vision"))
